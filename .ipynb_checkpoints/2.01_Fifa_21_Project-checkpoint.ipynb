{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e7f5439",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d774f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics as stats\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "fifa21_df_org=pd.read_csv(\"fifa21_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193eac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_headers(df):\n",
    "    df.columns = [col.lower().replace(' ','_') for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84258fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_ftin_to_cm(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : int(x.split(\"'\")[0])*30.48+int(x.split(\"'\")[1].replace(\"\\\"\",\"\"))*2.54)\n",
    "    df[col_name]=df[col_name].apply(lambda x : round(x,0))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae19919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lbs_to_kg(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : round(int(x.replace(\"lbs\",\"\"))*0.45359237,0))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd337bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_datecol_with_yearcol(df,col_name):\n",
    "    df[col_name]=pd.to_datetime(df[col_name],errors='coerce')\n",
    "    df[col_name+'_'+'year']=df[col_name].apply(lambda x : x.year)\n",
    "\n",
    "    # Drop position of the joined column\n",
    "    df.drop([col_name], axis=1,inplace=True)\n",
    "\n",
    "    # Check how many are NaN\n",
    "    df[col_name+'_'+'year'].isna().sum()\n",
    "\n",
    "    # Keep only the non NaN for joined_year\n",
    "    df = df[df[col_name+'_'+'year'].notna()]\n",
    "\n",
    "    # Change joined_year to int\n",
    "    df[col_name+'_'+'year']=df[col_name+'_'+'year'].apply(lambda x : int(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_currency_col_to_int(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : int(x.replace(\"€\",\"\").replace(\"K\",\"000\").replace(\"M\",\"000000\").replace(\".\",\"\")))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_year_range_to_cols(df,col_name):\n",
    "    df[col_name+'_start'] = \"\"\n",
    "    df[col_name+'_end'] = \"\"\n",
    "    df[col_name+'_start']=df[col_name].apply(lambda x : x.split(\"~\")[0].strip())\n",
    "    df[col_name+'_end']=df[col_name].apply(lambda x : np.nan if x.find('~') == -1 else x.split(\"~\")[1].strip())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e44ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_from_str_col(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : re.findall(\"\\d{4}\",x)[0] if len(re.findall(\"\\d{4}\",x))>0 else np.nan)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d64935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumup_operands(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : int(x.split(\"+\")[0])+int(x.split(\"+\")[1]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308a0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_cols_nan(df):\n",
    "    df=pd.DataFrame(df.isna().sum(),columns=['count'])\n",
    "    return df[df['count']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784f5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,filename):\n",
    "    # 1. Standardize header names.\n",
    "    df=standardize_headers(df)\n",
    "    \n",
    "    # 2. Drop position of the following columns\n",
    "    df.drop(['id','name','position','team_&_contract','loan_date_end'], axis=1,inplace=True)\n",
    "    \n",
    "    # 3. Converting Height to cm\n",
    "    df=convert_ftin_to_cm(df,'height')\n",
    "    \n",
    "    # 4. Convert weight in lbs to kgs\n",
    "    df=convert_lbs_to_kg(df,'weight')\n",
    "    \n",
    "    # 5. Convert joined col to Datetime\n",
    "    df=replace_datecol_with_yearcol(df,'joined')\n",
    "    \n",
    "    # 6. Convert value, wage and release_clause to float\n",
    "    df=convert_currency_col_to_int(df,'value')\n",
    "    df=convert_currency_col_to_int(df,'wage')\n",
    "    df=convert_currency_col_to_int(df,'release_clause')\n",
    "    \n",
    "    # 7. Add contract start and end date\n",
    "    df=split_year_range_to_cols(df,'contract')\n",
    "    \n",
    "    # 8. Add column is_on_loan\n",
    "    df['is_on_loan']=df['contract_start'].apply(lambda x : 0 if x.find('On Loan')==-1 else 1)\n",
    "    \n",
    "    # 9. Eliminate the ★ and convert to int\n",
    "    df['w/f']=df['w/f'].apply(lambda x : int(x.replace(\"★\",\"\")))\n",
    "    df['sm']=df['sm'].apply(lambda x : int(x.replace(\"★\",\"\")))\n",
    "    df['ir']=df['ir'].apply(lambda x : int(x.replace(\"★\",\"\")))\n",
    "    \n",
    "    # 10. Extract contract start date from contract_start column containing other strings\n",
    "    df=extract_year_from_str_col(df,'contract_start')\n",
    "    \n",
    "    # 11. Convert columns contract_start and contract_end to int\n",
    "    df['contract_start']=pd.to_numeric(df['contract_start'],errors='coerce')\n",
    "    df['contract_end']=pd.to_numeric(df['contract_end'],errors='coerce')\n",
    "    # Drop column contract\n",
    "    df.drop(['contract'], axis=1,inplace=True)\n",
    "    \n",
    "    # 12. Convert other string columns containing only ints\n",
    "    df.select_dtypes(include=object)\n",
    "    df['hits']=pd.to_numeric(df['hits'],errors='coerce')\n",
    "    \n",
    "    # 13. Convert skill columns to numeric after adding the bonus to a single integer value\n",
    "    skill_cols=['ls','st','rs','lw','lf','cf','rf','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb','gk']\n",
    "    for col in skill_cols:\n",
    "        df=sumup_operands(df,col)\n",
    "        \n",
    "    # 14. Check for NaNs\n",
    "    nan_rep_df=identify_cols_nan(df)\n",
    "    \n",
    "    # 15. Handling of NaNs for below columns:\n",
    "    \n",
    "    # We choose median value for Nan values in composure\n",
    "    df['composure'].value_counts()\n",
    "    df['composure'] = df['composure'].fillna(stats.median(df['composure']))\n",
    "\n",
    "    # We choose mode value for Nan values in a/w\n",
    "    df['a/w'].value_counts()\n",
    "    df['a/w'] = df['a/w'].fillna(stats.mode(df['a/w']))\n",
    "    \n",
    "    # We choose mode value for Nan values in d/w\n",
    "    df['d/w'].value_counts()\n",
    "    df['d/w'] = df['d/w'].fillna(stats.mode(df['d/w']))\n",
    "    \n",
    "    # We choose mode value for Nan values in hits\n",
    "    df['hits'].value_counts()\n",
    "    df['hits'] = df['hits'].fillna(stats.mode(df['hits']))\n",
    "    \n",
    "    # Remove Nans\n",
    "    df = df[df['contract_start'].notna()]\n",
    "    \n",
    "    # Export the cleaned dataset:\n",
    "    df.to_csv(filename+\".csv\",index=False)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029fb479",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa21_df=preprocess(fifa21_df_org,'fifa21_df_cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2dc06f",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Describe DataFrame.\n",
    "fifa21_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplots\n",
    "fifa21_df['foot'].value_counts().plot(kind='bar')\n",
    "\n",
    "# INFERENCE: Right Foot Players are dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa21_df['bp'].value_counts().plot(kind='bar')\n",
    "# INFERENCE: Center Back is the most dominant position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e98c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa21_df['a/w'].value_counts().plot(kind='bar')\n",
    "\n",
    "# INFERENCE: Medium Attacking Work Rate is the most dominant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1d0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa21_df['d/w'].value_counts().plot(kind='bar')\n",
    "\n",
    "# INFERENCE: Medium Defensive Work Rate is the most dominant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa21_df['joined_year'].value_counts().plot(kind='bar')\n",
    "\n",
    "# INFERENCE: Most players joined back in 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68e282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(fifa21_df['age'])\n",
    "\n",
    "# INFERENCE: Most players are in between 20's to 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c6b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(fifa21_df['weight'])\n",
    "# INFERENCE: Most players have an average weight of 75kgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=fifa21_df[\"age\"], y=fifa21_df[\"ova\"])\n",
    "# INFERENCE: A positive correlation between age and overall rating, although dispersed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=fifa21_df[\"skill\"], y=fifa21_df[\"ova\"])\n",
    "# INFERENCE: 2 distinct clusters of scattered points, although showing a slight positive correlation of skill and overall rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dbbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=fifa21_df[\"total_stats\"], y=fifa21_df[\"ova\"])\n",
    "# INFERENCE: 2 distinct clusters of scattered points, although showing a slight positive correlation of total_stats and overall rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=fifa21_df[\"base_stats\"], y=fifa21_df[\"ova\"])\n",
    "# INFERENCE: A strong positive correlation between base_stats and overall rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f2cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=fifa21_df[\"composure\"], y=fifa21_df[\"ova\"])\n",
    "# INFERENCE: A strong positive correlation between composure and overall rating, with bit of dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb0035",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=fifa21_df[\"reactions\"], y=fifa21_df[\"ova\"])\n",
    "# INFERENCE: A strong positive correlation between reactions and overall rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=fifa21_df[\"growth\"], y=fifa21_df[\"ova\"])\n",
    "# INFERENCE: A strong negative correlation between growth and overall rating, with ordered dispersion at distinct growth values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd4e6e4",
   "metadata": {},
   "source": [
    "# Feature Selection & Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import pickle\n",
    "isTrain=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33119ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the cleaned/transformed fifa dataset from the previous stage\n",
    "fifa21_df=pd.read_csv(\"fifa21_df_cleaned.csv\")\n",
    "# Dropping the unnecessary columns\n",
    "fifa21_df = fifa21_df.drop(['contract_start','contract_end','nationality','club'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definition for preparation/preprocessing of model input\n",
    "\n",
    "def preprocess_model_input(df,output_col=None,is_train_test_split=False):\n",
    "    # 1. Split the numerical, categorical and the output column:\n",
    "    X_num=df.select_dtypes(include=np.number)\n",
    "    X_cat=df.select_dtypes(include=object)\n",
    "    if output_col is not None:\n",
    "        y = X_num[output_col]\n",
    "        X_num = X_num.drop([output_col], axis=1)\n",
    "    \n",
    "    # 2. Normalizing data:\n",
    "    transformer = MinMaxScaler().fit(X_num)\n",
    "    X_normalized = transformer.transform(X_num)\n",
    "    X_normalized = pd.DataFrame(X_normalized,columns=X_num.columns)\n",
    "    \n",
    "    # 3. Encoding categorical columns:\n",
    "    if len(X_cat)>0:\n",
    "        encoder = OneHotEncoder().fit(X_cat)\n",
    "        encoded = encoder.transform(X_cat).toarray()\n",
    "        cols = encoder.get_feature_names_out(input_features=X_cat.columns)\n",
    "        onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "\n",
    "    # 4. Concatenating normalized numeric columns and encoded categorical columns\n",
    "\n",
    "    if len(X_cat)>0:\n",
    "        X = pd.concat([X_normalized, onehot_encoded], axis=1)\n",
    "    \n",
    "    else:\n",
    "        X = pd.concat([X_normalized], axis=1)\n",
    "        \n",
    "    # 5. Creating a Train-Test Split\n",
    "    if is_train_test_split:\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        if output_col is not None:\n",
    "            return X,y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "# Function for evaluating the model and displaying the metrics of the model accuracy\n",
    "\n",
    "def produce_metrics_lm(lm,X_test,y_test,isPrint=False):\n",
    "    predictions_test = lm.predict(X_test)\n",
    "    r2=round(r2_score(y_test, predictions_test),2)\n",
    "    mas=round(mean_absolute_error(y_test, predictions_test),2)\n",
    "    mse=round(mean_squared_error(y_test,predictions_test),2)\n",
    "    rmse=round(np.sqrt(mean_squared_error(y_test,predictions_test)),2)\n",
    "    if isPrint:\n",
    "        print(\"r2_score: \",r2)\n",
    "        print(\"mean absolute error :\",mas)\n",
    "        print(\"mean square error :\",mse)\n",
    "        print(\"root mean square error :\",rmse)\n",
    "    else:\n",
    "        return r2,mas,mse,rmse,predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### FEATURE SELECTION ##################\n",
    "# (involves selection methods: brute force (manual selection trials) + correlation matrix (along with identifying \n",
    "# Multicollinearity)) - total of 39 features + 1 output variable\n",
    "\n",
    "# A selection of 46 features was giving a raise to the accuracy by only +0.02, therefore we decided to stick with only 39 \n",
    "# features as below to limit the size of model.\n",
    "\n",
    "selected_features=[\n",
    "                    'age',\n",
    "                    'height',\n",
    "                    'weight',\n",
    "                    'value',\n",
    "                    'wage',\n",
    "                    'release_clause',\n",
    "                    'attacking',\n",
    "                    'crossing',\n",
    "                    'finishing',\n",
    "                    'heading_accuracy',\n",
    "                    'short_passing',\n",
    "                    'volleys',\n",
    "                    'skill',\n",
    "                    'dribbling',\n",
    "                    'curve',\n",
    "                    'fk_accuracy',\n",
    "                    'long_passing',\n",
    "                    'ball_control',\n",
    "                    'movement',\n",
    "                    'acceleration',\n",
    "                    'sprint_speed',\n",
    "                    'agility',\n",
    "                    'reactions',\n",
    "                    'balance',\n",
    "                    'power',\n",
    "                    'shot_power',\n",
    "                    'jumping',\n",
    "                    'stamina',\n",
    "                    'strength',\n",
    "                    'long_shots',\n",
    "                    'mentality',\n",
    "                    'aggression',\n",
    "                    'interceptions',\n",
    "                    'positioning',\n",
    "                    'vision',\n",
    "                    'penalties',\n",
    "                    'composure',\n",
    "                    'marking',\n",
    "                    'goalkeeping',\n",
    "                    'ova'\n",
    "                    ]\n",
    "\n",
    "fifa21_df_selected=fifa21_df[selected_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_model_input(fifa21_df_selected,'ova',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bd2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the training of the dataset on Linear Regression Model and save the model\n",
    "isTrain=True\n",
    "# Creating and fitting a Linear Regression Model\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "if isTrain==True:\n",
    "    filename = 'fifa21_lm.sav'\n",
    "    pickle.dump(lm, open(filename, 'wb'))\n",
    "else:\n",
    "    lm = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35586d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the model evaluation for Training and Test Dataset\n",
    "print(\"Training Metrics:\")\n",
    "produce_metrics_lm(lm,X_train,y_train,True)\n",
    "print()\n",
    "print(\"Test Metrics:\")\n",
    "produce_metrics_lm(lm,X_test,y_test,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa09baaa",
   "metadata": {},
   "source": [
    "# Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e773fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation dataset\n",
    "isTrain=False\n",
    "fifa21_df_validation=pd.read_csv(\"fifa21_validate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7bbd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the validation dataset for the cleaning and standardization, and drop the unnecessary columns\n",
    "fifa21_df_validation_cleaned=preprocess(fifa21_df_validation,'fifa21_df_valid_cleaned')\n",
    "fifa21_df_validation_cleaned = fifa21_df_validation_cleaned.drop(['contract_start','contract_end','nationality','club'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the necessary features needed for performing the prediction and later preprocess the DF for model preparation\n",
    "fifa21_df_validation_cleaned_selected=fifa21_df_validation_cleaned[selected_features]\n",
    "X_valid,y_valid=preprocess_model_input(fifa21_df_validation_cleaned_selected,'ova',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c00a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Linear Regression Model\n",
    "if isTrain==True:\n",
    "    filename = 'fifa21_lm.sav'\n",
    "    pickle.dump(lm, open(filename, 'wb'))\n",
    "else:\n",
    "    lm = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beff69d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the model evaluation for Validation Dataset\n",
    "print(\"Validation Metrics:\")\n",
    "produce_metrics_lm(lm,X_valid,y_valid,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
