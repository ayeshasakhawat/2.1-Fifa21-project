{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ce3b90c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stats\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "isTrain=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "898eafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa21_df=pd.read_csv('fifa21_df_cleaned.csv')\n",
    "fifa21_df = fifa21_df.drop(['contract_start','contract_end','nationality','club'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a0668992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_model_input(df,output_col=None,is_train_test_split=False):\n",
    "    # 1. Split the numerical, categorical and the output column:\n",
    "    X_num=df.select_dtypes(include=np.number)\n",
    "    X_cat=df.select_dtypes(include=object)\n",
    "    if output_col is not None:\n",
    "        y = X_num[output_col]\n",
    "        X_num = X_num.drop([output_col], axis=1)\n",
    "    \n",
    "    # 2. Normalizing data:\n",
    "    transformer = MinMaxScaler().fit(X_num)\n",
    "    X_normalized = transformer.transform(X_num)\n",
    "    X_normalized = pd.DataFrame(X_normalized,columns=X_num.columns)\n",
    "    \n",
    "    # 3. Encoding categorical columns:\n",
    "    encoder = OneHotEncoder().fit(X_cat)\n",
    "    encoded = encoder.transform(X_cat).toarray()\n",
    "    cols = encoder.get_feature_names_out(input_features=X_cat.columns)\n",
    "    onehot_encoded = pd.DataFrame(encoded, columns=cols)\n",
    "    \n",
    "    #######################################################\n",
    "    #X_normalized=X_normalized[['age','height','weight','growth','value','wage','release_clause','attacking','crossing','finishing','heading_accuracy','short_passing','volleys','skill','dribbling','curve','fk_accuracy','long_passing','ball_control','movement','acceleration','sprint_speed','agility','reactions','balance','power','shot_power','jumping','stamina','strength','long_shots','mentality','aggression','interceptions','positioning','vision','penalties','composure','defending','marking','standing_tackle','sliding_tackle','goalkeeping']]\n",
    "    # defending,standing_tackle,sliding_tackle is the culprit!\n",
    "    X_normalized=X_normalized[['age','height','weight','value','wage','release_clause','attacking','crossing','finishing','heading_accuracy','short_passing','volleys','skill','dribbling','curve','fk_accuracy','long_passing','ball_control','movement','acceleration','sprint_speed','agility','reactions','balance','power','shot_power','jumping','stamina','strength','long_shots','mentality','aggression','interceptions','positioning','vision','penalties','composure','marking','goalkeeping']]\n",
    "    #######################################################\n",
    "    \n",
    "    # 4. Concatenating normalized numeric columns and encoded categorical columns\n",
    "    \n",
    "    #######################################################\n",
    "    #X = pd.concat([X_normalized, onehot_encoded], axis=1)\n",
    "    X = pd.concat([X_normalized], axis=1)\n",
    "    #######################################################\n",
    "    if is_train_test_split:\n",
    "        # 5. Creating a Train-Test Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        if output_col is not None:\n",
    "            return X,y\n",
    "        else:\n",
    "            return X\n",
    "    \n",
    "def produce_metrics_lm(lm,X_test,y_test,isPrint=False):\n",
    "    predictions_test = lm.predict(X_test)\n",
    "    r2=r2_score(y_test, predictions_test),\n",
    "    mas=mean_absolute_error(y_test, predictions_test)\n",
    "    mse=mean_squared_error(y_test,predictions_test)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test,predictions_test))\n",
    "    if isPrint:\n",
    "        print(\"r2_score: \",r2)\n",
    "        print(\"mean absolute error :\",mas)\n",
    "        print(\"mean square error :\",mse)\n",
    "        print(\"root mean square error :\",rmse)\n",
    "    return r2,mas,mse,rmse,predictions_test\n",
    "\n",
    "def preprocess(df,filename):\n",
    "    # 1. Standardize header names.\n",
    "    df=standardize_headers(df)\n",
    "    \n",
    "    # 2. Drop position of the following columns\n",
    "    df.drop(['id','name','position','team_&_contract','loan_date_end'], axis=1,inplace=True)\n",
    "    \n",
    "    # 3. Converting Height to cm\n",
    "    df=convert_ftin_to_cm(df,'height')\n",
    "    \n",
    "    # 4. Convert weight in lbs to kgs\n",
    "    df=convert_lbs_to_kg(df,'weight')\n",
    "    \n",
    "    # 5. Convert joined col to Datetime\n",
    "    df=replace_datecol_with_yearcol(df,'joined')\n",
    "    \n",
    "    # 6. Convert value, wage and release_clause to float\n",
    "    df=convert_currency_col_to_int(df,'value')\n",
    "    df=convert_currency_col_to_int(df,'wage')\n",
    "    df=convert_currency_col_to_int(df,'release_clause')\n",
    "    \n",
    "    # 7. Add contract start and end date\n",
    "    df=split_year_range_to_cols(df,'contract')\n",
    "    \n",
    "    # 8. Add column is_on_loan\n",
    "    df['is_on_loan']=df['contract_start'].apply(lambda x : 0 if x.find('On Loan')==-1 else 1)\n",
    "    \n",
    "    # 9. Eliminate the ★ and convert to int\n",
    "    df['w/f']=df['w/f'].apply(lambda x : int(x.replace(\"★\",\"\")))\n",
    "    df['sm']=df['sm'].apply(lambda x : int(x.replace(\"★\",\"\")))\n",
    "    df['ir']=df['ir'].apply(lambda x : int(x.replace(\"★\",\"\")))\n",
    "    \n",
    "    # 10. Extract contract start date from contract_start column containing other strings\n",
    "    df=extract_year_from_str_col(df,'contract_start')\n",
    "    \n",
    "    # 11. Convert columns contract_start and contract_end to int\n",
    "    df['contract_start']=pd.to_numeric(df['contract_start'],errors='coerce')\n",
    "    df['contract_end']=pd.to_numeric(df['contract_end'],errors='coerce')\n",
    "    # Drop column contract\n",
    "    df.drop(['contract'], axis=1,inplace=True)\n",
    "    \n",
    "    # 12. Convert other string columns containing only ints\n",
    "    df.select_dtypes(include=object)\n",
    "    df['hits']=pd.to_numeric(df['hits'],errors='coerce')\n",
    "    \n",
    "    # 13. Convert skill columns to numeric after adding the bonus to a single integer value\n",
    "    skill_cols=['ls','st','rs','lw','lf','cf','rf','rw','lam','cam','ram','lm','lcm','cm','rcm','rm','lwb','ldm','cdm','rdm','rwb','lb','lcb','cb','rcb','rb','gk']\n",
    "    for col in skill_cols:\n",
    "        df=sumup_operands(df,col)\n",
    "        \n",
    "    # 14. Check for NaNs\n",
    "    nan_rep_df=identify_cols_nan(df)\n",
    "    \n",
    "    # 15. Handling of NaNs for below columns:\n",
    "    \n",
    "    # We choose median value for Nan values in composure\n",
    "    df['composure'].value_counts()\n",
    "    df['composure'] = df['composure'].fillna(stats.median(df['composure']))\n",
    "\n",
    "    # We choose mode value for Nan values in a/w\n",
    "    df['a/w'].value_counts()\n",
    "    df['a/w'] = df['a/w'].fillna(stats.mode(df['a/w']))\n",
    "    \n",
    "    # We choose mode value for Nan values in d/w\n",
    "    df['d/w'].value_counts()\n",
    "    df['d/w'] = df['d/w'].fillna(stats.mode(df['d/w']))\n",
    "    \n",
    "    # We choose mode value for Nan values in hits\n",
    "    df['hits'].value_counts()\n",
    "    df['hits'] = df['hits'].fillna(stats.mode(df['hits']))\n",
    "    \n",
    "    # Remove Nans\n",
    "    df = df[df['contract_start'].notna()]\n",
    "    \n",
    "    # Export the cleaned dataset:\n",
    "    df.to_csv(filename+\".csv\",index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def standardize_headers(df):\n",
    "    df.columns = [col.lower().replace(' ','_') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def identify_cols_nan(df):\n",
    "    df=pd.DataFrame(df.isna().sum(),columns=['count'])\n",
    "    return df[df['count']>0]\n",
    "\n",
    "def sumup_operands(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : int(x.split(\"+\")[0])+int(x.split(\"+\")[1]))\n",
    "    return df\n",
    "\n",
    "def extract_year_from_str_col(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : re.findall(\"\\d{4}\",x)[0] if len(re.findall(\"\\d{4}\",x))>0 else np.nan)\n",
    "    return df\n",
    "\n",
    "def split_year_range_to_cols(df,col_name):\n",
    "    df[col_name+'_start'] = \"\"\n",
    "    df[col_name+'_end'] = \"\"\n",
    "    df[col_name+'_start']=df[col_name].apply(lambda x : x.split(\"~\")[0].strip())\n",
    "    df[col_name+'_end']=df[col_name].apply(lambda x : np.nan if x.find('~') == -1 else x.split(\"~\")[1].strip())\n",
    "    return df\n",
    "\n",
    "def convert_currency_col_to_int(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : int(x.replace(\"€\",\"\").replace(\"K\",\"000\").replace(\"M\",\"000000\").replace(\".\",\"\")))\n",
    "    return df\n",
    "\n",
    "def replace_datecol_with_yearcol(df,col_name):\n",
    "    df[col_name]=pd.to_datetime(df[col_name],errors='coerce')\n",
    "    df[col_name+'_'+'year']=df[col_name].apply(lambda x : x.year)\n",
    "\n",
    "    # Drop position of the joined column\n",
    "    df.drop([col_name], axis=1,inplace=True)\n",
    "\n",
    "    # Check how many are NaN\n",
    "    df[col_name+'_'+'year'].isna().sum()\n",
    "\n",
    "    # Keep only the non NaN for joined_year\n",
    "    df = df[df[col_name+'_'+'year'].notna()]\n",
    "\n",
    "    # Change joined_year to int\n",
    "    df[col_name+'_'+'year']=df[col_name+'_'+'year'].apply(lambda x : int(x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def convert_lbs_to_kg(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : round(int(x.replace(\"lbs\",\"\"))*0.45359237,0))\n",
    "    return df\n",
    "\n",
    "def convert_ftin_to_cm(df,col_name):\n",
    "    df[col_name]=df[col_name].apply(lambda x : int(x.split(\"'\")[0])*30.48+int(x.split(\"'\")[1].replace(\"\\\"\",\"\"))*2.54)\n",
    "    df[col_name]=df[col_name].apply(lambda x : round(x,0))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0fa2ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_model_input(fifa21_df,'ova',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "29c83d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "isTrain=True\n",
    "# Creating and fitting a Linear Regression Model\n",
    "lm = linear_model.LinearRegression()\n",
    "lm.fit(X_train,y_train)\n",
    "if isTrain==True:\n",
    "    filename = 'fifa21_lm.sav'\n",
    "    pickle.dump(lm, open(filename, 'wb'))\n",
    "else:\n",
    "    lm = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1a2ea3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "r2_score:  (0.8923673787532845,)\n",
      "mean absolute error : 1.7378951512541703\n",
      "mean square error : 5.019027366488217\n",
      "root mean square error : 2.24031858593554\n",
      "Test Metrics:\n",
      "r2_score:  (0.8935489519416288,)\n",
      "mean absolute error : 1.7322744412364557\n",
      "mean square error : 5.167513999364535\n",
      "root mean square error : 2.273216663533095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.8935489519416288,),\n",
       " 1.7322744412364557,\n",
       " 5.167513999364535,\n",
       " 2.273216663533095,\n",
       " array([62.40021557, 70.7072977 , 71.0724332 , ..., 75.24935656,\n",
       "        68.90827255, 55.68155459]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Training Metrics:\")\n",
    "produce_metrics_lm(lm,X_train,y_train,True)\n",
    "print(\"Test Metrics:\")\n",
    "produce_metrics_lm(lm,X_test,y_test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "45e88b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "isTrain=False\n",
    "fifa21_df_validation=pd.read_csv(\"fifa21_validate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3c36a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifa21_df_validation_cleaned=preprocess(fifa21_df_validation,'fifa21_df_valid_cleaned')\n",
    "fifa21_df_validation_cleaned = fifa21_df_validation_cleaned.drop(['contract_start','contract_end','nationality','club'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "93f6acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid,y_valid=preprocess_model_input(fifa21_df_validation_cleaned,'ova',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fb06ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Linear Regression Model\n",
    "if isTrain==True:\n",
    "    filename = 'fifa21_lm.sav'\n",
    "    pickle.dump(lm, open(filename, 'wb'))\n",
    "else:\n",
    "    lm = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fc92c3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "r2_score:  (0.8661428579667874,)\n",
      "mean absolute error : 1.9179418662566536\n",
      "mean square error : 6.144826729915442\n",
      "root mean square error : 2.478876102171192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.8661428579667874,),\n",
       " 1.9179418662566536,\n",
       " 6.144826729915442,\n",
       " 2.478876102171192,\n",
       " array([65.15958201, 65.85396632, 50.08343017, ..., 71.94452079,\n",
       "        64.98371144, 62.27879893]))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Validation Metrics:\")\n",
    "produce_metrics_lm(lm,X_valid,y_valid,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
